import pandas as pd
from bs4 import BeautifulSoup
from tkinter import Tk, filedialog, messagebox
from tqdm import tqdm
from playwright.sync_api import sync_playwright

root = Tk()
root.withdraw()


file_path = filedialog.askopenfilename(
    title="Select Excel File",
    filetypes=[("Excel files", "*.xlsx *.xls")]
)

if not file_path:
    messagebox.showinfo("Cancelled", "No file selected. Exiting.")
    exit()


try:
    df = pd.read_excel(file_path)
except Exception as e:
    messagebox.showerror("Error", f"Failed to read the Excel file:\n{e}")
    exit()

url_column_name = 'URL'
canonical_column_name = 'Canonical url'
bt = 'Browser title'
seo = 'SEO description'
lp = 'Landing page'
meta_tag_column_name = 'Meta Robots'


if url_column_name not in df.columns:
    messagebox.showerror("Missing Column", f"Column '{url_column_name}' not found in the Excel file.")
    exit()


for col in [canonical_column_name, bt, seo, lp, meta_tag_column_name]:
    if col not in df.columns:
        df[col] = pd.Series(dtype='str')


df[bt] = df[bt].astype('string')
df[lp] = df[lp].astype('string')
df[canonical_column_name] = df[canonical_column_name].astype('string')
df[seo] = df[seo].astype('string')
df[meta_tag_column_name] = df[meta_tag_column_name].astype('string')


with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    page = browser.new_page()

 
    for idx, url in tqdm(enumerate(df[url_column_name]), total=len(df), desc="Processing URLs", colour="white"):
        try:
            page.goto(url, timeout=30000)
            page.wait_for_timeout(3000) 

            df.at[idx, bt] = page.title()

            df.at[idx, lp] = page.url

            soup = BeautifulSoup(page.content(), "html.parser")

            canonical_tag = soup.find("link", rel="canonical")
            df.at[idx, canonical_column_name] = canonical_tag.get("href") if canonical_tag else "Not Found"

            seo_desc = soup.find("meta", attrs={"name": "description"})
            df.at[idx, seo] = seo_desc.get("content") if seo_desc else "Not Found"

            robots_tag = soup.find("meta", attrs={"name": "robots"})
            df.at[idx, meta_tag_column_name] = robots_tag.get("content") if robots_tag else "Not Found"

        except Exception as e:
            print(f"\n⚠️ Error at index {idx}, URL: {url}\n{e}")
            df.at[idx, bt] = "Error"
            df.at[idx, lp] = "Error"
            df.at[idx, canonical_column_name] = "Error"
            df.at[idx, seo] = "Error"
            df.at[idx, meta_tag_column_name] = "Error"

    browser.close()

success_count = df[bt].apply(lambda x: x not in ["Error", "Empty URL"]).sum()
print(f"\n✅ Completed. {success_count} URLs processed successfully out of {len(df)}.")

save_path = filedialog.asksaveasfilename(
    title="Save Updated Excel File",
    defaultextension=".xlsx",
    filetypes=[("Excel files", "*.xlsx *.xls")]
)

if save_path:
    df.to_excel(save_path, index=False)
    messagebox.showinfo("Success", f"Updated file saved to:\n{save_path}")
else:
    messagebox.showinfo("Cancelled", "No save location selected. Data not saved.")
